#TASK1:
part a)
1.The Mathematical Objection:Based on mathematical theorems like Godel’s incompleteness theorem,there are truths that machines cannot prove,implying a fundamental difference between 
human minds and machines.
2.The Argument from Consciousness:Critics argue that machines,regardless of their sophistication,cannot possess consciousness,emotions,or self-awareness.While AI has advanced
 the question of whether they can truly experience consciousness remains unresolved.
3.Lady Lovelace’s Objection:Ada Lovelace contended that machines can only perform tasks they are explicitly programmed to do and cannot originate new ideas.
4.The Argument from Informality of Behavior:This objection posits that human behavior is too complex and informal to be captured by any set of rules or algorithms.
5.The Continuity of the Nervous System: Turing acknowledged that the human brain operates in a continuous manner,whereas digital computers function discretely.
Questions about the fidelity and completeness of such simulations in capturing the nuances of human cognition persist.
part b)
1.The Mathematical Objection(Godel’s Theorem):This theorem is partially valid.While Godel's theorem applies to formal systems,AI systems today do not solely rely on formal logic,
as they still lack true understanding.
2.The Argument from Consciousness:It is Still valid. There is no evidence that AI systems, including large language models and neural networks, possess actual consciousness or
self-awareness. 
3.Lady Lovelace’s Objection (Creativity):Largely refuted. AI can now generate novel ideas, art, and even scientific hypotheses.However, whether this constitutes true creativity
remains debatable.
4.The Argument from Informality of Behavior:It is still partially valid.AI can handle complex tasks but struggles with generalization beyond its training data.
5.The Continuity of the Nervous System:It is mostly refuted. While digital computers work discretely, continuous processes can be simulated with arbitrary precision. 
part c)
Turing’s prediction that a computer would have a 30% chance of passing a five-minute Turing Test by the year 2000 was ambitious but not entirely unreasonable.
By 2000,chatbots like ELIZA and ALICE had made progress in simulating human conversation,but they were still relatively easy to distinguish from humans.
They relied on pattern matching and predefined scripts rather than true understanding.
However, Turing’s estimate wasn’t far off. In 2014, Eugene Goostman, a chatbot simulating a 13-year-old Ukrainian boy, reportedly “passed”
the Turing Test by convincing 33% of judges in a five-minute conversation. This suggests that Ai wasnt far behind.
Modern AI, particularly large language models like ChatGPT, has significantly surpassed this threshold. 
While AI still lacks true comprehension, it can now sustain human-like conversations over extended periods,making Turing’s prediction quite reasonable.

Task #2:
1.ping pong, AI have shown to be capable of playing at beginner level. However, achieving consistent performance for professional level is difficut due to 
keeping track of rapid motion tracking,precise control and ability to anticipate and repond to unpredictible shots.
2. Playing bridge at competitive level is difficult for Al as obtaining knowledge about any hidden environment and when to communicate with other is complex to train.
3. Humor's deeply rooted in human experience,cultural nuances and emotional intellegence which an Al can't currently comprehend so to invoke laughter Al needs 
to understand when and what joke to say which it cannot currently do.
4.Al can be used to analyse legal document in short time and assist with legal research but it can only give advice with current data and without any knowledge of 
legal reasoning and the dynamic nature of law. Al may not be able to catch up with giving legal advice in area of law.
5. Forming new Mathematical Theorems require abstract thinking and intuition" which is beyond Al capabilities. 
However, Al has assisted in proving over 1200 mathematical theorems so it does have potential in this domain.
6. There have been many Al assisted robots used in surgenes such as DaVinc Surgical System. 
These Al system assist in visualization and dextority in humans.However, Al lacks in knowledge of human anatomy,making real-time decisions in unpredictible situbations
and there are also ethic considerations so they are only used to assist human experts and not replace them.
7. Al can easily perform repititive tasks in controlled environments but unloading a dishwasher at home presents challenges.Differences in dishwasher design.dish arrangements
and household layouts require the level of adaptability that a robot cannot currently achieve.
8.Al and robotics have been integrated into construction for tasks like bricklayering, 3D printing of building components and site surveying. 
However,building the complete building from scratch is beyond the capabilities of Al due to lack of complex decision making.adaptation to environmental decisions and 
variability and unpredictability of construction sites.

Task #3
Domain: Movie Recommendation Al:
*) It is an Al that suggests movie based on user preferences, viewing history and trends.The agent analyze user interaction,
ratings and demographic data to provide personalized recommandations.
•) Accessible Environments:User data
In accessible environments:User emotions and preferences which are not stated
•)Episodic Environment:Each recommendation is independent.
•) Non-episodic Environment:Systems learn with human interaction
•)Static:None
•) Non Static:System adapts a user preference changes and new movie release.
wower preference Chunger and new
•)Continous Environment:The system updates recommendation in real-time based on new date.
Agent Used:Learning-based Agent to implement collaborative filtering content based filtering and allow agent to learn.

#Task#4:
1.False:Even with partial information, an agent can still be perfectly rational if it makes the best possible decision based on the information it has.
Example:A poker-playing AI does not have full knowledge of opponents' cards but can still play optimally using probability and game theory.
2.True:A pure reflex agent only reacts to its immediate perception and does not consider history or future consequences, which can be problematic.
Example:A maze-solving robot that follows a simple rule like "turn right when possible" may get stuck in loops and fail to reach the goal.
3.False:Different agents may have different goals, and some environments might inherently involve uncertainty, making it impossible for all agents to be rational.
Counterexample:A competitive game where agents have opposing objectives—one agent's rational move might be irrational for another.
4.False:The agent function maps from percept histories to actions, whereas the agent program operates on actual inputs received from sensors,which may be encoded differently.
Example: A self-driving car's agent function may theoretically map all possible road situations to actions, while the agent program processes sensor data 
and makes decisions in real-time.
5.False:Some agent functions may be too complex or infeasible to implement due to computational limitations.
Example:A chess-playing agent that perfectly calculates all possible future moves would require unrealistic computational power.
6.True:If the environment rewards exploration or randomization, a uniformly random agent could be rational.
Example:In an adversarial game where unpredictability is an advantage a random strategy may be rational.
7.True:If the agent's decision-making strategy aligns with optimal behavior in multiple environments, it can be rational in both.
Example:A thermostat that maintains a room at 22°C by turning heating on or off is rational as long as it achieves the goal of maintaining temperature.

#Task#5:

